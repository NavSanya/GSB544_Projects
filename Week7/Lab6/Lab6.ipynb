{
 "cells": [
  {
   "cell_type": "raw",
   "id": "14581b82",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Practice Activity 7.1\"\n",
    "author: \"Nav Sanya Anand\"\n",
    "format:\n",
    "        html:\n",
    "                toc: true\n",
    "                embed-resources: true\n",
    "theme: sketchy\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bbd87d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b880b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Hitters.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d567294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (322, 20)\n",
      "AtBat         0\n",
      "Hits          0\n",
      "HmRun         0\n",
      "Runs          0\n",
      "RBI           0\n",
      "Walks         0\n",
      "Years         0\n",
      "CAtBat        0\n",
      "CHits         0\n",
      "CHmRun        0\n",
      "CRuns         0\n",
      "CRBI          0\n",
      "CWalks        0\n",
      "League        0\n",
      "Division      0\n",
      "PutOuts       0\n",
      "Assists       0\n",
      "Errors        0\n",
      "Salary       59\n",
      "NewLeague     0\n",
      "dtype: int64\n",
      "After drop: (263, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial shape:\", df.shape)\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop rows with missing Salary (only variable with NAs)\n",
    "df = df.dropna(subset=[\"Salary\"])\n",
    "print(\"After drop:\", df.shape)\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8303b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Salary\"])\n",
    "y = df[\"Salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81cdb95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify categorical and numeric columns\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=np.number).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "240138bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd8c856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numeric features, one-hot encode categoricals\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(drop=\"first\"), cat_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"  # keep any unexpected columns\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66708d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_mse(pipeline, Xtr, ytr, cv=5):\n",
    "    scores = cross_val_score(pipeline, Xtr, ytr, cv=KFold(cv, shuffle=True, random_state=42),\n",
    "                             scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "    return -scores.mean(), scores.std()\n",
    "\n",
    "def evaluate_full(model, X_train, X_test, y_train, y_test, name=\"model\"):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"R2_test\": r2_score(y_test, y_pred),\n",
    "        \"RMSE_test\": mean_squared_error(y_test, y_pred),\n",
    "        \"MAE_test\": mean_absolute_error(y_test, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76744650",
   "metadata": {},
   "source": [
    "# Part I: Different Model Specs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ebbe19",
   "metadata": {},
   "source": [
    "### A. Regression without regularization\n",
    "Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary linear regression\n",
    "\n",
    "Fit this pipeline to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "Use cross-validation to estimate the MSE you would expect if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ecaed57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OLS] CV MSE: 148524.4273448546 (± 88857.66290489696)\n",
      "{'Model': 'OLS', 'R2_test': 0.4110795465741335, 'RMSE_test': 127487.05257542129, 'MAE_test': 216.23960331813112}\n"
     ]
    }
   ],
   "source": [
    "ols_pipe = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "ols_cv_mse_mean, ols_cv_mse_sd = cv_mse(ols_pipe, X_train, y_train, cv=5)\n",
    "ols_results = evaluate_full(ols_pipe, X_train, X_test, y_train, y_test, \"OLS\")\n",
    "print(f\"[OLS] CV MSE: {ols_cv_mse_mean} (± {ols_cv_mse_sd})\")\n",
    "print(ols_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d509ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_pipe.fit(X_train, y_train)\n",
    "# names after preprocessing\n",
    "num_names = num_cols\n",
    "cat_names = []\n",
    "if len(cat_cols) > 0:\n",
    "    cat_names = list(\n",
    "        ols_pipe.named_steps[\"preprocessor\"]\n",
    "        .named_transformers_[\"cat\"]\n",
    "        .get_feature_names_out(cat_cols)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a426832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top OLS coefficients by |magnitude|:\n",
      "       Feature  Coefficient\n",
      "10       CRuns   602.973835\n",
      "1         Hits   379.226590\n",
      "7       CAtBat  -318.631805\n",
      "0        AtBat  -252.645370\n",
      "11        CRBI   238.251038\n",
      "12      CWalks  -179.250015\n",
      "8        CHits  -136.216934\n",
      "5        Walks   113.427805\n",
      "16    League_N   113.414763\n",
      "17  Division_W  -100.028262\n"
     ]
    }
   ],
   "source": [
    "feat_names_all = num_names + cat_names + (X_train.columns.difference(num_cols + cat_cols).tolist() if False else [])\n",
    "coefs_ols = ols_pipe.named_steps[\"model\"].coef_\n",
    "coef_df_ols = pd.DataFrame({\"Feature\": feat_names_all, \"Coefficient\": coefs_ols})\n",
    "print(\"\\nTop OLS coefficients by |magnitude|:\")\n",
    "print(coef_df_ols.reindex(coef_df_ols.Coefficient.abs().sort_values(ascending=False).index).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c97863",
   "metadata": {},
   "source": [
    "### B. Ridge regression\n",
    "Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary ridge regression\n",
    "\n",
    "Use cross-validation to tune the \n",
    " hyperparameter.\n",
    "\n",
    "Fit the pipeline with your chosen \n",
    " to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "Report the MSE you would expect if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2efbadd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pipe = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", Ridge(random_state=42))\n",
    "])\n",
    "\n",
    "ridge_grid = {\"model__alpha\": np.logspace(-3, 3, 25)}\n",
    "ridge_cv = GridSearchCV(\n",
    "    ridge_pipe, ridge_grid,\n",
    "    cv=KFold(5, shuffle=True, random_state=42),\n",
    "    scoring=\"neg_mean_squared_error\", n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efe97800",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv.fit(X_train, y_train)\n",
    "ridge_best = ridge_cv.best_estimator_\n",
    "ridge_cv_mse = -ridge_cv.best_score_\n",
    "ridge_results = evaluate_full(ridge_best, X_train, X_test, y_train, y_test,\n",
    "                              f\"Ridge (alpha={ridge_cv.best_params_['model__alpha']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45f891ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Ridge] best alpha = 177.82794100389228\n",
      "[Ridge] CV MSE: 116116.53242454273\n",
      "{'Model': 'Ridge (alpha=177.82794100389228)', 'R2_test': 0.29735824210969497, 'RMSE_test': 152104.96801181967, 'MAE_test': 235.1071060065175}\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n[Ridge] best alpha = {ridge_cv.best_params_['model__alpha']}\")\n",
    "print(f\"[Ridge] CV MSE: {ridge_cv_mse}\")\n",
    "print(ridge_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c393791",
   "metadata": {},
   "source": [
    "### C. Lasso Regression\n",
    "Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary ridge regression\n",
    "\n",
    "Use cross-validation to tune the \n",
    " hyperparameter.\n",
    "\n",
    "Fit the pipeline with your chosen \n",
    " to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "Report the MSE you would expect if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "521d883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_pipe = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", Lasso(max_iter=10000, random_state=42))\n",
    "])\n",
    "\n",
    "lasso_grid = {\"model__alpha\": np.logspace(-3, 1, 25)}\n",
    "lasso_cv = GridSearchCV(\n",
    "    lasso_pipe, lasso_grid,\n",
    "    cv=KFold(5, shuffle=True, random_state=42),\n",
    "    scoring=\"neg_mean_squared_error\", n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "270d8127",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv.fit(X_train, y_train)\n",
    "lasso_best = lasso_cv.best_estimator_\n",
    "lasso_cv_mse = -lasso_cv.best_score_\n",
    "lasso_results = evaluate_full(lasso_best, X_train, X_test, y_train, y_test,\n",
    "                              f\"LASSO (alpha={lasso_cv.best_params_['model__alpha']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26715ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LASSO] best alpha = 10.0\n",
      "[LASSO] CV MSE: 124277.08593290819\n",
      "{'Model': 'LASSO (alpha=10.0)', 'R2_test': 0.3264794378430288, 'RMSE_test': 145800.93256880206, 'MAE_test': 227.4795114246595}\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n[LASSO] best alpha = {lasso_cv.best_params_['model__alpha']}\")\n",
    "print(f\"[LASSO] CV MSE: {lasso_cv_mse}\")\n",
    "print(lasso_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce491a8",
   "metadata": {},
   "source": [
    "### D. Elastic Net\n",
    "Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary ridge regression\n",
    "\n",
    "Use cross-validation to tune the \n",
    " and \n",
    " hyperparameters.\n",
    "\n",
    "Fit the pipeline with your chosen hyperparameters to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "Report the MSE you would expect if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf4ad584",
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_pipe = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", ElasticNet(max_iter=10000, random_state=42))\n",
    "])\n",
    "\n",
    "enet_grid = {\n",
    "    \"model__alpha\": np.logspace(-3, 1, 12),\n",
    "    \"model__l1_ratio\": np.linspace(0.1, 0.9, 9)\n",
    "}\n",
    "enet_cv = GridSearchCV(\n",
    "    enet_pipe, enet_grid,\n",
    "    cv=KFold(5, shuffle=True, random_state=42),\n",
    "    scoring=\"neg_mean_squared_error\", n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce65049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_cv.fit(X_train, y_train)\n",
    "enet_best = enet_cv.best_estimator_\n",
    "enet_cv_mse = -enet_cv.best_score_\n",
    "enet_results = evaluate_full(enet_best, X_train, X_test, y_train, y_test,\n",
    "                             f\"ElasticNet (alpha={enet_cv.best_params_['model__alpha']}, l1={enet_cv.best_params_['model__l1_ratio']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d1cb4333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ElasticNet] best params = {'model__alpha': np.float64(1.873817422860385), 'model__l1_ratio': np.float64(0.4)}\n",
      "[ElasticNet] CV MSE: 116214.42321967045\n",
      "{'Model': 'ElasticNet (alpha=1.873817422860385, l1=0.4)', 'R2_test': 0.29578743958229825, 'RMSE_test': 152445.0088156853, 'MAE_test': 235.97705384223224}\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n[ElasticNet] best params = {enet_cv.best_params_}\")\n",
    "print(f\"[ElasticNet] CV MSE: {enet_cv_mse}\")\n",
    "print(enet_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a156ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model comparison:\n",
      "                                          Model   R2_test      RMSE_test  \\\n",
      "1              Ridge (alpha=177.82794100389228)  0.297358  152104.968012   \n",
      "3  ElasticNet (alpha=1.873817422860385, l1=0.4)  0.295787  152445.008816   \n",
      "2                            LASSO (alpha=10.0)  0.326479  145800.932569   \n",
      "0                                           OLS  0.411080  127487.052575   \n",
      "\n",
      "     MAE_test         CV_MSE  \n",
      "1  235.107106  116116.532425  \n",
      "3  235.977054  116214.423220  \n",
      "2  227.479511  124277.085933  \n",
      "0  216.239603  148524.427345  \n"
     ]
    }
   ],
   "source": [
    "# Collect comparison\n",
    "model_comp = pd.DataFrame([ols_results, ridge_results, lasso_results, enet_results])\n",
    "model_comp[\"CV_MSE\"] = [ols_cv_mse_mean, ridge_cv_mse, lasso_cv_mse, enet_cv_mse]\n",
    "print(\"\\nModel comparison:\")\n",
    "print(model_comp.sort_values(\"CV_MSE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2d19b6",
   "metadata": {},
   "source": [
    "# Part II. Variable Selection\n",
    "Based on the above results, decide on:\n",
    "\n",
    "Which numeric variable is most important.\n",
    "\n",
    "Which five numeric variables are most important\n",
    "\n",
    "Which categorical variable is most important\n",
    "\n",
    "For each of the four model specifications, compare the following possible feature sets:\n",
    "\n",
    "Using only the one best numeric variable.\n",
    "\n",
    "Using only the five best variables.\n",
    "\n",
    "Using the five best numeric variables and their interactions with the one best categorical variable.\n",
    "\n",
    "Report which combination of features and model performed best, based on the validation metric of MSE.\n",
    "\n",
    "(Note: \n",
    " and \n",
    " must be re-tuned for each feature set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58ce3734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b35441",
   "metadata": {},
   "source": [
    "# Part III. Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99e8b29",
   "metadata": {},
   "source": [
    "### A. Ridge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cb9d63",
   "metadata": {},
   "source": [
    "### B. LASSO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55fa607",
   "metadata": {},
   "source": [
    "### C. Elastic Net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8402746f",
   "metadata": {},
   "source": [
    "# Part IV: Final Model\n",
    "Fit your final best pipeline on the full dataset, and summarize your results in a few short sentences and a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c95945f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
